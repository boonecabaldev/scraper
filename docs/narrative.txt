I am iterating over hat images (called HatNode) on https://newtrade6699.x.yupoo.com/albums. For each image I am scraping the image and its href.

I am scraping https://newtrade6699.x.yupoo.com/albums/156268944?uid=1&isSubCate=false&referrercate=3515821 and from div.image__imagewrap i need to use scrapy to scrape data-src (name it data_src instead), data-origin-src, data-path, and src. What are the selectors for this?

print(len(response.xpath('//div[@class="image__imagewrap"]')))
print(len(response.xpath("//img[@class='autocover image__img image__landscape']")))

i'm using sqlite3 in this project. i need sql to create two tables:

HatNodes
- an auto-incremented primary key column called Id
- a text column called url
- a text column called local_file_path

HatLeaf
- an auto-incremented primary key column called Id
- a text column called url
- a text column called local_file_path


if my spider crawls multiple pages, should i use multiple spiders or just methods in a single spider?

Whether to use multiple spiders or just methods in a single spider depends on the structure of the website and the nature of the data you're scraping.

If the pages you're crawling are similar in structure and contain similar types of data, it's usually more efficient to use a single spider with multiple methods. You can define methods to parse different types of pages, and use Scrapy's request callback system to pass between them.

If the pages are very different in structure, or if they contain different types of data that you want to process differently, it might be more manageable to use multiple spiders. This can keep your code more organized and easier to maintain.

In general, if the pages are part of the same website and are related in some way, it's usually a good idea to start with a single spider and only split it into multiple spiders if it becomes too complex or unwieldy.

//div[@class='showindex__children']//a[@class='album__main']//div[@class='album__imgwrap']//img[@class='album__absolute album__img autocover']/@src
